{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"name":"python","version":"3.6.6","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"colab":{"provenance":[]}},"nbformat_minor":0,"nbformat":4,"cells":[{"cell_type":"markdown","source":["In this kernel, I will try building a CNN from scratch for multi-class classification for the fruits dataset. In this dataset, we have a total of 55244 images which are divided into two folders - training set of 41322 images and testing set of 13877 images. The size of the given images is 100 * 100. We have 81 classes of fruits.\n","Let's get started!"],"metadata":{"_uuid":"11c05a044f27e0cfd9d38927523d86f9fcd1ef02","id":"Zp6LA5wvBbcO"}},{"cell_type":"code","source":["# First, we are going to load the file names and their respective target labels into numpy array!\n","from sklearn.datasets import load_files\n","import numpy as np\n","\n","train_dir = '../input/fruits-360_dataset/fruits-360/Training'\n","test_dir = '../input/fruits-360_dataset/fruits-360/Test'\n","\n","def load_dataset(path):\n","    data = load_files(path)\n","    files = np.array(data['filenames'])\n","    targets = np.array(data['target'])\n","    target_labels = np.array(data['target_names'])\n","    return files,targets,target_labels\n","\n","x_train, y_train,target_labels = load_dataset(train_dir)\n","x_test, y_test,_ = load_dataset(test_dir)\n","print('Loading complete!')\n","\n","print('Training set size : ' , x_train.shape[0])\n","print('Testing set size : ', x_test.shape[0])"],"metadata":{"_uuid":"8ae6b0f622f3371e629d3bc916d881b11b7a5bf8","trusted":true,"id":"u70n8Rw6BbcQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's confirm the number of classes :p\n","no_of_classes = len(np.unique(y_train))\n","no_of_classes"],"metadata":{"_uuid":"f09063e1d62bcf1fe28eb840ee93fd95fcfdb6ed","trusted":true,"id":"eu2cfGfEBbcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print(y_train[0:10])\n","# target labels are numbers corresponding to class label. We need to change them to a vector of 81 elements."],"metadata":{"_uuid":"27cf6d93da0e851e97f341be0dd7060eba55ce0f","trusted":true,"id":"bakR3uEIBbcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from keras.utils import np_utils\n","y_train = np_utils.to_categorical(y_train,no_of_classes)\n","y_test = np_utils.to_categorical(y_test,no_of_classes)\n","y_train[0] # Note that only one element has value 1(corresponding to its label) and others are 0."],"metadata":{"_uuid":"299c14e9e0a8fc0e5fde71bf144a012dee02160b","trusted":true,"id":"5EfOmAmlBbcR"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Now, we have to divide the validation set into test and validation set\n","x_test,x_valid = x_test[7000:],x_test[:7000]\n","y_test,y_vaild = y_test[7000:],y_test[:7000]\n","print('Vaildation X : ',x_valid.shape)\n","print('Vaildation y :',y_vaild.shape)\n","print('Test X : ',x_test.shape)\n","print('Test y : ',y_test.shape)"],"metadata":{"_uuid":"726a160122475e7d47e0c00bf617b7a5c0838ba6","trusted":true,"id":"xwMC-yBBBbcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":359},"id":"z9lU35C8CEgk","executionInfo":{"status":"error","timestamp":1687335607576,"user_tz":-330,"elapsed":111920,"user":{"displayName":"Mukilan DK","userId":"08790023869925773187"}},"outputId":"9e67b5f4-d718-437e-bf5d-8cf34e6aef03"},"execution_count":1,"outputs":[{"output_type":"error","ename":"MessageError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mMessageError\u001b[0m                              Traceback (most recent call last)","\u001b[0;32m<ipython-input-1-d5df0069828e>\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mgoogle\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcolab\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdrive\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mdrive\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'/content/drive'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36mmount\u001b[0;34m(mountpoint, force_remount, timeout_ms, readonly)\u001b[0m\n\u001b[1;32m    101\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mmount\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_ms\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m120000\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mreadonly\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    102\u001b[0m   \u001b[0;34m\"\"\"Mount your Google Drive at the specified mountpoint path.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m   return _mount(\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0mmountpoint\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m       \u001b[0mforce_remount\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mforce_remount\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/drive.py\u001b[0m in \u001b[0;36m_mount\u001b[0;34m(mountpoint, force_remount, timeout_ms, ephemeral, readonly)\u001b[0m\n\u001b[1;32m    130\u001b[0m   )\n\u001b[1;32m    131\u001b[0m   \u001b[0;32mif\u001b[0m \u001b[0mephemeral\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 132\u001b[0;31m     _message.blocking_request(\n\u001b[0m\u001b[1;32m    133\u001b[0m         \u001b[0;34m'request_auth'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m{\u001b[0m\u001b[0;34m'authType'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'dfs_ephemeral'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m     )\n","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mblocking_request\u001b[0;34m(request_type, request, timeout_sec, parent)\u001b[0m\n\u001b[1;32m    174\u001b[0m       \u001b[0mrequest_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrequest\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparent\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparent\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mexpect_reply\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    175\u001b[0m   )\n\u001b[0;32m--> 176\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0mread_reply_from_input\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrequest_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtimeout_sec\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m","\u001b[0;32m/usr/local/lib/python3.10/dist-packages/google/colab/_message.py\u001b[0m in \u001b[0;36mread_reply_from_input\u001b[0;34m(message_id, timeout_sec)\u001b[0m\n\u001b[1;32m    101\u001b[0m     ):\n\u001b[1;32m    102\u001b[0m       \u001b[0;32mif\u001b[0m \u001b[0;34m'error'\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 103\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mMessageError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreply\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'error'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    104\u001b[0m       \u001b[0;32mreturn\u001b[0m \u001b[0mreply\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'data'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    105\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mMessageError\u001b[0m: Error: credential propagation was unsuccessful"]}]},{"cell_type":"code","source":["x_train[0]\n","# training data is just file names of images. We need to convert them into pixel matrix."],"metadata":{"_uuid":"aa2cbb8c65386cef369abc49c7a4c1da3957d08e","trusted":true,"id":"zfQcINtDBbcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# We just have the file names in the x set. Let's load the images and convert them into array.\n","from keras.preprocessing.image import array_to_img, img_to_array, load_img\n","\n","def convert_image_to_array(files):\n","    images_as_array=[]\n","    for file in files:\n","        # Convert to Numpy Array\n","        images_as_array.append(img_to_array(load_img(file)))\n","    return images_as_array\n","\n","x_train = np.array(convert_image_to_array(x_train))\n","print('Training set shape : ',x_train.shape)\n","\n","x_valid = np.array(convert_image_to_array(x_valid))\n","print('Validation set shape : ',x_valid.shape)\n","\n","x_test = np.array(convert_image_to_array(x_test))\n","print('Test set shape : ',x_test.shape)\n","\n","print('1st training image shape ',x_train[0].shape)\n"],"metadata":{"scrolled":true,"_uuid":"1b3ab256679300f07d026017477092ebc5c71594","trusted":true,"id":"wzCf-8ZWBbcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["print('1st training image as array',x_train[0]) # don't worry if you see only 255s..\n","# there are elements will other values too :p"],"metadata":{"_uuid":"fb44a8c41693a8e14332cc734dd2ced9d5582986","trusted":true,"id":"1O4NZuG4BbcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# time to re-scale so that all the pixel values lie within 0 to 1\n","x_train = x_train.astype('float32')/255\n","x_valid = x_valid.astype('float32')/255\n","x_test = x_test.astype('float32')/255\n","x_train[0]"],"metadata":{"_uuid":"a9bbd173bdc8646ebafeeb31e492c80199683c72","trusted":true,"id":"TLHz_B3vBbcS"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Let's visualize the first 10 training images!\n","import matplotlib.pyplot as plt\n","\n","fig = plt.figure(figsize =(30,5))\n","for i in range(10):\n","    ax = fig.add_subplot(2,5,i+1,xticks=[],yticks=[])\n","    ax.imshow(np.squeeze(x_train[i]))\n","# Yummy fruits ;)"],"metadata":{"_uuid":"4cb2bff712654024215ef79585dba06dd0114396","scrolled":true,"trusted":true,"id":"Djevm9nmBbcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Simple CNN from scratch - we are using 3 Conv layers followed by maxpooling layers.\n","# At the end we add dropout, flatten and some fully connected layers(Dense).\n","\n","from keras.models import Sequential\n","from keras.layers import Conv2D,MaxPooling2D\n","from keras.layers import Activation, Dense, Flatten, Dropout\n","from keras.preprocessing.image import ImageDataGenerator\n","from keras.callbacks import ModelCheckpoint\n","from keras import backend as K\n","\n","model = Sequential()\n","model.add(Conv2D(filters = 16, kernel_size = 2,input_shape=(100,100,3),padding='same'))\n","model.add(Activation('relu'))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","model.add(Conv2D(filters = 32,kernel_size = 2,activation= 'relu',padding='same'))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","model.add(Conv2D(filters = 64,kernel_size = 2,activation= 'relu',padding='same'))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","model.add(Conv2D(filters = 128,kernel_size = 2,activation= 'relu',padding='same'))\n","model.add(MaxPooling2D(pool_size=2))\n","\n","model.add(Dropout(0.3))\n","model.add(Flatten())\n","model.add(Dense(150))\n","model.add(Activation('relu'))\n","model.add(Dropout(0.4))\n","model.add(Dense(81,activation = 'softmax'))\n","model.summary()"],"metadata":{"_uuid":"d14849fa59a55c57dfdd9622a4d9bcc90de8971b","trusted":true,"id":"Ta6HujUHBbcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["model.compile(loss='categorical_crossentropy',\n","              optimizer='rmsprop',\n","              metrics=['accuracy'])\n","print('Compiled!')"],"metadata":{"_uuid":"dff4d3931ad4ff2748d7681a9767007877694b12","trusted":true,"id":"CkXKdo8DBbcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["batch_size = 32\n","\n","checkpointer = ModelCheckpoint(filepath = 'cnn_from_scratch_fruits.hdf5', verbose = 1, save_best_only = True)\n","\n","history = model.fit(x_train,y_train,\n","        batch_size = 32,\n","        epochs=30,\n","        validation_data=(x_valid, y_vaild),\n","        callbacks = [checkpointer],\n","        verbose=2, shuffle=True)"],"metadata":{"_uuid":"2ac38a4408414793435002ff4af1ab25bbf082a8","trusted":true,"id":"aQTM-IbtBbcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# load the weights that yielded the best validation accuracy\n","model.load_weights('cnn_from_scratch_fruits.hdf5')"],"metadata":{"_uuid":"03edb7196563f35ee053d3306f594ece4f50139b","trusted":true,"id":"ACjRB2yjBbcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# evaluate and print test accuracy\n","score = model.evaluate(x_test, y_test, verbose=0)\n","print('\\n', 'Test accuracy:', score[1])\n","#98% accuracy !!"],"metadata":{"_uuid":"4b9df1b9ce5cf750cff33b8ab975acee72c6aa4d","trusted":true,"id":"_vlOrTjcBbcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# Let's visualize test prediction.\n","\n","y_pred = model.predict(x_test)\n","\n","# plot a random sample of test images, their predicted labels, and ground truth\n","fig = plt.figure(figsize=(16, 9))\n","for i, idx in enumerate(np.random.choice(x_test.shape[0], size=16, replace=False)):\n","    ax = fig.add_subplot(4, 4, i + 1, xticks=[], yticks=[])\n","    ax.imshow(np.squeeze(x_test[idx]))\n","    pred_idx = np.argmax(y_pred[idx])\n","    true_idx = np.argmax(y_test[idx])\n","    ax.set_title(\"{} ({})\".format(target_labels[pred_idx], target_labels[true_idx]),\n","                 color=(\"green\" if pred_idx == true_idx else \"red\"))"],"metadata":{"_uuid":"d45b1a4b675f0c1189e8cbdd0876badac6fa1d6e","trusted":true,"id":"WbD2z3_1BbcT"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["#Finally lets visualize the loss and accuracy wrt epochs\n","\n","import matplotlib.pyplot as plt\n","plt.figure(1)\n","\n"," # summarize history for accuracy\n","\n","plt.subplot(211)\n","plt.plot(history.history['acc'])\n","plt.plot(history.history['val_acc'])\n","plt.title('model accuracy')\n","plt.ylabel('accuracy')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","\n"," # summarize history for loss\n","\n","plt.subplot(212)\n","plt.plot(history.history['loss'])\n","plt.plot(history.history['val_loss'])\n","plt.title('model loss')\n","plt.ylabel('loss')\n","plt.xlabel('epoch')\n","plt.legend(['train', 'test'], loc='upper left')\n","plt.show()"],"metadata":{"_uuid":"f4754c40e12c2070c3721e46fba5465df9719151","trusted":true,"id":"aMBI1_ZlBbcU"},"execution_count":null,"outputs":[]}]}