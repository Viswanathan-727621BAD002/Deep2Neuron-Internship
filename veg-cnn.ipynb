{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# Import libraries\nimport numpy as np\nimport matplotlib.pyplot as plt\nimport tensorflow as tf\nfrom tensorflow import keras\nfrom keras.layers import *\nfrom keras.models import *\nfrom keras.preprocessing import image\nfrom keras.preprocessing.image import ImageDataGenerator\nimport os, shutil\nimport warnings\nwarnings.filterwarnings('ignore')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:44:25.397388Z","iopub.execute_input":"2022-01-08T16:44:25.398444Z","iopub.status.idle":"2022-01-08T16:44:30.062868Z","shell.execute_reply.started":"2022-01-08T16:44:25.398319Z","shell.execute_reply":"2022-01-08T16:44:30.062078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Visualise the Images","metadata":{}},{"cell_type":"code","source":"# Let's plot a few images\ntrain_path = \"../input/vegetable-image-dataset/Vegetable Images/train\"\nvalidation_path = \"../input/vegetable-image-dataset/Vegetable Images/validation\"\ntest_path = \"../input/vegetable-image-dataset/Vegetable Images/test\"\n\nimage_categories = os.listdir('../input/vegetable-image-dataset/Vegetable Images/train')\n\ndef plot_images(image_categories):\n    \n    # Create a figure\n    plt.figure(figsize=(12, 12))\n    for i, cat in enumerate(image_categories):\n        \n        # Load images for the ith category\n        image_path = train_path + '/' + cat\n        images_in_folder = os.listdir(image_path)\n        first_image_of_folder = images_in_folder[0]\n        first_image_path = image_path + '/' + first_image_of_folder\n        img = image.load_img(first_image_path)\n        img_arr = image.img_to_array(img)/255.0\n        \n        \n        # Create Subplot and plot the images\n        plt.subplot(4, 4, i+1)\n        plt.imshow(img_arr)\n        plt.title(cat)\n        plt.axis('off')\n        \n    plt.show()\n\n# Call the function\nplot_images(image_categories)\n        ","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:44:30.064478Z","iopub.execute_input":"2022-01-08T16:44:30.064754Z","iopub.status.idle":"2022-01-08T16:44:36.539149Z","shell.execute_reply.started":"2022-01-08T16:44:30.064712Z","shell.execute_reply":"2022-01-08T16:44:36.537478Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Prepare the Dataset","metadata":{}},{"cell_type":"code","source":"# Creating Image Data Generator for train, validation and test set\n\n# 1. Train Set\ntrain_gen = ImageDataGenerator(rescale = 1.0/255.0) # Normalise the data\ntrain_image_generator = train_gen.flow_from_directory(\n                                            train_path,\n                                            target_size=(150, 150),\n                                            batch_size=32,\n                                            class_mode='categorical')\n\n# 2. Validation Set\nval_gen = ImageDataGenerator(rescale = 1.0/255.0) # Normalise the data\nval_image_generator = train_gen.flow_from_directory(\n                                            validation_path,\n                                            target_size=(150, 150),\n                                            batch_size=32,\n                                            class_mode='categorical')\n\n# 3. Test Set\ntest_gen = ImageDataGenerator(rescale = 1.0/255.0) # Normalise the data\ntest_image_generator = train_gen.flow_from_directory(\n                                            test_path,\n                                            target_size=(150, 150),\n                                            batch_size=32,\n                                            class_mode='categorical')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:44:36.540142Z","iopub.execute_input":"2022-01-08T16:44:36.540387Z","iopub.status.idle":"2022-01-08T16:44:39.364199Z","shell.execute_reply.started":"2022-01-08T16:44:36.540356Z","shell.execute_reply":"2022-01-08T16:44:39.363418Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Print the class encodings done by the generators\nclass_map = dict([(v, k) for k, v in train_image_generator.class_indices.items()])\nprint(class_map)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:44:39.366395Z","iopub.execute_input":"2022-01-08T16:44:39.366839Z","iopub.status.idle":"2022-01-08T16:44:39.375038Z","shell.execute_reply.started":"2022-01-08T16:44:39.3668Z","shell.execute_reply":"2022-01-08T16:44:39.373629Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Building a CNN model","metadata":{}},{"cell_type":"code","source":"# Build a custom sequential CNN model\n\nmodel = Sequential() # model object\n\n# Add Layers\nmodel.add(Conv2D(filters=32, kernel_size=3, strides=1, padding='same', activation='relu', input_shape=[150, 150, 3]))\nmodel.add(MaxPooling2D(2, ))\nmodel.add(Conv2D(filters=64, kernel_size=3, strides=1, padding='same', activation='relu'))\nmodel.add(MaxPooling2D(2))\n\n# Flatten the feature map\nmodel.add(Flatten())\n\n# Add the fully connected layers\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dropout(0.25))\nmodel.add(Dense(128, activation='relu'))\nmodel.add(Dense(15, activation='softmax'))\n\n# print the model summary\nmodel.summary()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:44:39.377401Z","iopub.execute_input":"2022-01-08T16:44:39.378733Z","iopub.status.idle":"2022-01-08T16:44:41.674987Z","shell.execute_reply.started":"2022-01-08T16:44:39.378695Z","shell.execute_reply":"2022-01-08T16:44:41.674278Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Compile and fit the model\nearly_stopping = keras.callbacks.EarlyStopping(patience=5) # Set up callbacks\nmodel.compile(optimizer='Adam', loss='categorical_crossentropy', metrics='accuracy')\nhist = model.fit(train_image_generator, \n                 epochs=100, \n                 verbose=1, \n                 validation_data=val_image_generator, \n                 steps_per_epoch = 15000//32, \n                 validation_steps = 3000//32, \n                 callbacks=early_stopping)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:44:41.676281Z","iopub.execute_input":"2022-01-08T16:44:41.676687Z","iopub.status.idle":"2022-01-08T16:56:24.973171Z","shell.execute_reply.started":"2022-01-08T16:44:41.676651Z","shell.execute_reply":"2022-01-08T16:56:24.972423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"**Model trained for 15 Epochs**","metadata":{}},{"cell_type":"code","source":"# Plot the error and accuracy\nh = hist.history\nplt.style.use('ggplot')\nplt.figure(figsize=(10, 5))\nplt.plot(h['loss'], c='red', label='Training Loss')\nplt.plot(h['val_loss'], c='red', linestyle='--', label='Validation Loss')\nplt.plot(h['accuracy'], c='blue', label='Training Accuracy')\nplt.plot(h['val_accuracy'], c='blue', linestyle='--', label='Validation Accuracy')\nplt.xlabel(\"Number of Epochs\")\nplt.legend(loc='best')\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:56:24.975861Z","iopub.execute_input":"2022-01-08T16:56:24.976072Z","iopub.status.idle":"2022-01-08T16:56:33.604213Z","shell.execute_reply.started":"2022-01-08T16:56:24.976041Z","shell.execute_reply":"2022-01-08T16:56:33.603552Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Predict the accuracy for the test set\nmodel.evaluate(test_image_generator)","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:56:33.605462Z","iopub.execute_input":"2022-01-08T16:56:33.605878Z","iopub.status.idle":"2022-01-08T16:56:58.884165Z","shell.execute_reply.started":"2022-01-08T16:56:33.605841Z","shell.execute_reply":"2022-01-08T16:56:58.883491Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Testing the Model\ntest_image_path = '../input/vegetable-image-dataset/Vegetable Images/test/Broccoli/1011.jpg'\n\ndef generate_predictions(test_image_path, actual_label):\n    \n    # 1. Load and preprocess the image\n    test_img = image.load_img(test_image_path, target_size=(150, 150))\n    test_img_arr = image.img_to_array(test_img)/255.0\n    test_img_input = test_img_arr.reshape((1, test_img_arr.shape[0], test_img_arr.shape[1], test_img_arr.shape[2]))\n\n    # 2. Make Predictions\n    predicted_label = np.argmax(model.predict(test_img_input))\n    predicted_vegetable = class_map[predicted_label]\n    plt.figure(figsize=(4, 4))\n    plt.imshow(test_img_arr)\n    plt.title(\"Predicted Label: {}, Actual Label: {}\".format(predicted_vegetable, actual_label))\n    plt.grid()\n    plt.axis('off')\n    plt.show()\n\n# call the function\ngenerate_predictions(test_image_path, actual_label='Brocoli')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T17:14:14.898474Z","iopub.execute_input":"2022-01-08T17:14:14.899158Z","iopub.status.idle":"2022-01-08T17:14:15.02412Z","shell.execute_reply.started":"2022-01-08T17:14:14.89912Z","shell.execute_reply":"2022-01-08T17:14:15.023368Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Let's test the model on an image from an external source\n!wget \"https://www.dropbox.com/s/i020rz847u8bq09/beans.jpg?dl=0\"","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:56:59.10972Z","iopub.execute_input":"2022-01-08T16:56:59.110462Z","iopub.status.idle":"2022-01-08T16:57:01.175398Z","shell.execute_reply.started":"2022-01-08T16:56:59.110424Z","shell.execute_reply":"2022-01-08T16:57:01.174644Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!wget \"https://www.dropbox.com/s/lge1plvr4mg5w7y/potato_2.jpg?dl=0\"","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:57:01.177749Z","iopub.execute_input":"2022-01-08T16:57:01.178497Z","iopub.status.idle":"2022-01-08T16:57:03.157904Z","shell.execute_reply.started":"2022-01-08T16:57:01.17845Z","shell.execute_reply":"2022-01-08T16:57:03.157098Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate predictions for external images\nexternal_image_path_1 = \"./beans.jpg?dl=0\"\ngenerate_predictions(external_image_path_1, actual_label='Bean')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:57:03.159721Z","iopub.execute_input":"2022-01-08T16:57:03.160009Z","iopub.status.idle":"2022-01-08T16:57:03.304377Z","shell.execute_reply.started":"2022-01-08T16:57:03.159964Z","shell.execute_reply":"2022-01-08T16:57:03.303667Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Generate predictions for external image\nexternal_image_path_2 = \"./potato_2.jpg?dl=0\"\ngenerate_predictions(external_image_path_2, actual_label='Potato')","metadata":{"execution":{"iopub.status.busy":"2022-01-08T16:57:03.305799Z","iopub.execute_input":"2022-01-08T16:57:03.306156Z","iopub.status.idle":"2022-01-08T16:57:03.418323Z","shell.execute_reply.started":"2022-01-08T16:57:03.306123Z","shell.execute_reply":"2022-01-08T16:57:03.417621Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"> ## T*he model performs well on both internal as well as external test images. In the upcoming notebook edits, I will implement various concepts like Data Augmentation and Transfer Learning and prepare a comparison between all these models. I hope you find the notebook informative. Please do share your feedback in the comment section and please do upvote it, if you found it helpful. Thanks and Happy Learning :)*","metadata":{}}]}